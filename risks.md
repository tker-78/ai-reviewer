# ドキュメンレビューアプリケーション

## リスク一覧と対応策一覧

1. レビュー観点の固定化
	•	リスク: JSONスキーマに観点を固定すると、追加・修正が運用負荷になる。現場のレビュー観点と乖離する可能性。
	•	対応策: 観点をDB/リポジトリで管理し、UIから編集可能にする「観点カタログ」を設計。

⸻

2. LLM移行時の非互換性
	•	リスク: Vertex AI → Ollama 移行時に、API形式や量子化方式の違いでPoC資産が流用できない。
	•	対応策: 早期に「抽象化されたLLM呼び出し層」を実装し、プロンプト入出力形式を統一。

⸻

3. セキュリティ監査リスク
	•	リスク: 一時保存やログに個人情報が残存し、社内セキュリティレビューに抵触。
	•	対応策:
	•	アップロードデータは暗号化（KMS/AES）＋期限付きストレージ
	•	監査ログはWORM（Write Once Read Many）や署名で改ざん防止

⸻

4. 用語集運用の負荷
	•	リスク: RAG用語集を手作業更新すると、抜け漏れが多発し精度が低下。
	•	対応策: 未知語抽出や高頻度ワード解析を自動化し、「用語候補リスト」を自動生成。

⸻

5. UI移行リスク
	•	リスク: PoC (Streamlit) と正式版 (Vue.js) のUI仕様が乖離し、作り直しコスト増。
	•	対応策: 画面遷移図とレビュー結果の表示形式を早期に固め、Streamlit版も同じUXで実装。

⸻

6. GPUリソース不足
	•	リスク: 社内GPUが少なく、同時アクセス時に処理が滞る。
	•	対応策:
	•	負荷試験をPoC段階で実施
	•	非同期処理（Queue + Worker構成）でスループットを確保
	•	CPUフォールバックを検討

⸻

7. レビュー精度の未定義
	•	リスク: 「課長・部長レベルのレビュー」の精度を定量評価できず、成果が曖昧。
	•	対応策: ゴールドスタンダード（実レビュー結果）をサンプル化し、人間評価＋自動指標（ROUGE/BLEU等）で定期検証。

⸻

8. 責任所在の不明確化
	•	リスク: LLM出力をそのまま利用され、誤りの責任がAIに転嫁される。
	•	対応策:
	•	UIに「AIは提案のみ。最終判断は人間」と明示
	•	ログに「承認者情報」を必須記録

⸻
